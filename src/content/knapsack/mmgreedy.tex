The modified greedy algorithm returns the best solution between the greedy solution and the best singleton.
Since scanning all pairs of elements rather than just singletons does not affect the running time of the modified greedy algorithm a natural question to ask is whether considering pairs of elements result in strictly better algorithm.
Here we do not give a complete answer to this question but we are able to improve our analysis for this algorithm. 

The \emph{modified modified greedy} algorithm~\ref{alg:mmgreedy} 
\footnote{A paraphrase on the ``ultimate ultimate weapon'' from \cite{ninjago2017}}
is similar to the  modified greedy algorithm, 
except it considers the best pair of element rather than the best singleton element.


\begin{algorithm}[H]
\label{alg:mmgreedy}
\caption{Modified$^2$ Greedy$(U, f, c)$}

$S \leftarrow \text{greedy}(U, f, c)$
\\
$T \leftarrow \arg\max\{S, \arg\max_{e_1, e_2 \in U}f(\{e_1, e_2\})\}$
\\
\Return{T}
\end{algorithm}

We now analyze its performance.

\begin{theorem}
	The Modified$^2$ Greedy (Algorithm~\ref{alg:mmgreedy}) achieves an approximation of $(1-e^{-(1/2 + \epsilon)})$ where $0 < e \leq 1/6$ is an absolute constant.
\end{theorem}

\def\eps{0.104}
\begin{proof}
Let $\epsilon > 0$ an absolute constant to be determined later.
If there is a pair of elements $e_1, e_2 \in U$ whose value is high enough, i.e., $f(\{e_1, e_2\}) \geq (1 - e^{-1/2 + \epsilon})f(O)$, the theorem follows.
Thus, let us assume that $f(\{e_1, e_2\}) < (1 - e^{-1/2 + \epsilon})f(O)$ for every $e_1, e_2 \in U$.
Similarly to the proof of Theorem~\ref{theorem:mgreedy}, we can assume that the greedy algorithm discards at least three elements from $O$, i.e., $|S \setminus O| \geq 3$.
Otherwise, we are guaranteed that $f(T) \geq 0.5f(O)$.
% 
Let $a$ be the first element in $O$ that was dropped by the algorithm, 
and let $A$ be the set of elements chosen by the algorithm just before dropping $a$.
% 
If $f(A) \geq (1 - e^{-(1/2 + \epsilon)})f(O)$ the theorem holds.
Otherwise denote $f(A) = (1 - e^{-(1/2 + \epsilon - \delta)})f(O)$ where $0 < \delta \leq 1/2 + \epsilon$.
% 
Lemma~\ref{lemma:sub-main} implies that: 
\begin{equation}
	\label{mmgreedy:ineq1}
	c(A) \leq (0.5 + \epsilon - \delta)c(O),
\end{equation}
otherwise $f(A) > (1-e^{-(1/2 + \epsilon - \delta)})f(O)$.
Moreover, since $a$ was dropped we confirm that:
\begin{equation}
	\label{mmgreedy:ineq2}
	c(a) > (0.5 -\epsilon + \delta)c(O),
\end{equation}
since $c(A \cup \{a\}) > \beta \geq c(O)$.

We say that an element, $e$, is \emph{big} if $c(e) \geq (1/4 + \epsilon/2 - \delta/2)c(O)$, 
otherwise it is \emph{small}.
Note that $a$ is big since $\epsilon \leq 1/6$ and $\delta > 0$.

Note that $O\setminus\{a\}$ contains at most one big element (if that is not the case then the size of two big elements is at least $(1/2 + \epsilon - \delta)c(O)$), in contradiction to \ref{mmgreedy:ineq2}.

, thus the algorithm drops 
at least one small element from $O$. 
Let $b$ be the first such element, and let $B$ be the set of elements chosen by the 
algorithm right after dropping $a$ and just before dropping $b$.
Also denote by $C$ the subset of small elements in $O$, 
i.e. $C = \{e \in O : c(e) < (1/4 + \epsilon/2 - \delta/2)c(O)\}$.
Again, in order to proof the theorem, we infer bounds on size and value.
We start by bounding the size:

\begin{align}
\label{mmgreedy:ineq3}
c(C) \leq (0.5 + \epsilon - \delta)c(O)
\end{align}

Inequality \ref{mmgreedy:ineq1} upper bound the size of $A$ and is due to Lemma~\ref{lemma:sub-main} since if it does not hold then $f(A) > (1 - e^{-(1/2 + \epsilon - \delta)})f(O)$.
Inequality \ref{mmgreedy:ineq2} lower bound the size of $a$ and is implied from the fact the $a$ was dropped by the greedy algorithm.
Inequality~\ref{mmgreedy:ineq3} upper bound the size of the small elements and follows from the fact the $a$ is not small.
% 
The above inequalities derive a lower bound on the size of $B$:
\begin{equation}
	\label{mmgreedy:lower-bound-cB}
	c(B) \geq (1/4 - 3\epsilon/2 + 3\delta/2)c(O)
\end{equation}

Now we bound value:

\begin{align}
	\label{mmgreedy:ineq4}
	f(C) \geq e^{-1/2 + \epsilon}f(O)
	\\
	\label{mmgreedy:lower-bound-B-given-A}
	f(B|A) \geq 
	(1-e^{-\frac{1-6\epsilon+6\delta}{2+4\epsilon-4\delta}})
	\left[
	e^{-(1/2 + \epsilon)}
	- (1 - e^{-(1/2 + \epsilon - \delta)})
	\right]f(O)
	\\
	\label{mmgreedy:ineq7}
	f(T) \geq \max_\epsilon \min \{(1 - e^{-(0.5 + \epsilon)})f(O), \min_{\delta} f(A) + f(B|A)\}
\end{align}

Inequality~\ref{mmgreedy:ineq4} lower bounds the value of the small elements and it follows from the submodularity of $f$, the fact that there are at most two big elements in an optimal solution, and our assumption that their value is at most $(1 - e^{-1/2 + \epsilon})f(O)$.
% 
Inequality~\ref{mmgreedy:lower-bound-B-given-A} lower bounds the marginal value of $B$ with respect to $A$ and follows by applying Lemma~\ref{lemma:sub-main} on $B$ and $C$.
% 
The last inequality captures the fact that either all elements in $O$ are smaller than
$(0.5 + \epsilon)c(O)$ or there is one element in $O$ larger than $(0.5 + \epsilon)c(O)$.
% 
Substituting $(f(A) = 1 - e^{-(1/2 + \epsilon - \delta)})f(O)$ into the last inequality, using $f(B|A) \ge \left[
e^{-(1/2 + \epsilon)}
- (1 - e^{-(1/2 + \epsilon - \delta)})
\right]
(1-e^{-\frac{1-6\epsilon+6\delta}{2+4\epsilon-4\delta}})f(O)$,
and setting (say) $\epsilon = \eps$ gives the desired result 
as one can verifies and as can be seen in Figure~\ref{fig:mmgreedy}.

\end{proof}

\begin{figure}
\caption{
\label{fig:mmgreedy}
Modified Modified Greedy Approximation Ratio ($\epsilon = \eps$)
}
\begin{tikzpicture}
\begin{axis}[
	width=\textwidth
	,domain=0:0.49
	,ymax=.7
	,xmax=.51
	,xlabel=$\delta$
	,xtick distance=0.1
	,ytick distance=0.1
	,axis lines=left
	,grid=both
	,grid style={
		draw=gray!20
	}
	,minor tick num=5
	,legend pos=south west
	,legend entries={
		$f(A)$
		,$f(B|A)$
		,$f(A) + f(B|A)$
		,$1-e^{-(0.5 + \epsilon)}$
	}
]
  \addplot[line blue]{1-exp(-(0.5 + \eps -x))};
  \addplot[line red]{
  	(1 - exp(-(1 - 6 * \eps + 6 * x)/(2 + 4 * \eps - 4 * x)))
  	*
  	(exp(-(0.5 + \eps)) - 1 + exp(-(0.5 + \eps - x)))
  };
  \addplot[line teal]{
  	1-exp(-(0.5 + \eps -x))
  	+
  	(1 - exp(-(1 - 6 * \eps + 6 * x)/(2 + 4 * \eps - 4 * x)))
  	*
  	(exp(-(0.5 + \eps)) - 1 + exp(-(0.5 + \eps - x)))
  };
  \addplot[line brown]{
  	1-exp(-(0.5 + \eps))
  };
\end{axis}
\end{tikzpicture}
\end{figure}

\textbf{Upper Bound}
We show that the approximation ratio of the modified modified greedy algorithm is at most $0.5$.
To see this consider the following instance of the budgeted maximum coverage problem:
Let the elements be $X = \{x_1, \dots, x_{2n}\}$, 
and a collection of subsets over $a$, $\mathcal{S} = \{S_1, \dots, S_{n + 1}\} \cup \{S\}$,
where for each $1 \leq i \leq n + 1$, $S_i = \{x_i\}$, and $c(S_i) = 1$. 
Also, set $S = \{x_{n + 2}, \dots, x_{2n}\}$, and $c(S) = n$.
Finally, for each $x \in X$ set $w(x) = 1$ and set the budget for this instance to be $2n$.
One can verify that the modified modified algorithm will return a solution of value $n + 1$
While taking $S$ along with any other $n$ subsets yields a solution of value $2n - 1$.  



