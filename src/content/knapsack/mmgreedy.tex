The modified greedy algorithm returns the best solution between the greedy solution and the best singleton.
Since scanning all pairs of elements rather than just singletons does not affect the running time of the modified greedy algorithm a natural question to ask is whether considering pairs of elements result in strictly better algorithm.
Here we do not give a complete answer to this question but we are able to improve our analysis for this algorithm. 

The \emph{modified modified greedy} algorithm~\ref{alg:mmgreedy} 
\footnote{A paraphrase on the ``ultimate ultimate weapon'' from \cite{ninjago2017}}
is similar to the  modified greedy algorithm, 
except it considers the best pair of element rather than the best singleton element.


\begin{algorithm}[H]
\label{alg:mmgreedy}

\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}

\Input{$U = \{e_1, \dots, e_n\}$, $f:2^U\to \mathbb{R}_+$, $c:U \to \mathbb{R}_+$}
\Output{$S \subseteq U$}

$S \leftarrow \text{greedy}(U, f, c)$
\\
\Return{$\arg\max\{S, \displaystyle{\arg\max_{e_1, e_2 \in U}}f(\{e_1, e_2\})\}$}
\caption{Modified Modified Greedy Algorithm}
\end{algorithm}

We now analyze its performance.
Let $\epsilon > 0$ a constant to be determined latter on, and let $T$ be the output of 
the algorithm.

\begin{theorem}
$f(T) \geq 1 - e^{-(1/2 + \epsilon)}$
\end{theorem}

\def\eps{0.104}
\begin{proof}
We can assume that $f(\{e_1, e_2\}) \leq (1 - e^{-1/2 + \epsilon})f(O)$ 
for every $e_1, e_2 \in U$ or otherwise the proof holds.
Note, also, that if $|O \setminus S| \leq 2$ then $f(T) \geq 0.5f(O)$.
Thus we assume the algorithm drops at least three elements from $O$ during its running.
Let $a$ be the first element in $O$ that was dropped by the algorithm, 
and let $A$ be the set of elements chosen by the algorithm just before dropping $a$.
If $f(A) \geq (1 - e^{-(1/2 + \epsilon)})f(O)$ the theorem holds, 
otherwise denote $f(A) = (1 - e^{-(1/2 + \epsilon - \delta)})f(O)$.
We say that an element, $e$, is \emph{expensive} if $c(e) \geq (1/4 + \epsilon/2 - \delta/2)c(O)$, 
otherwise it is \emph{cheap}.
Observe that $O$ contains at most two expensive elements, thus the algorithm drops 
at least one cheap element from $O$. 
Let $b$ be the first such element, and let $B$ be the set of elements chosen by the 
algorithm right after dropping $a$ and just before dropping $b$.
Also denote by $C$ the subset of cheap elements in $O$, 
i.e. $C = \{e \in O : c(e) < (1/4 + \epsilon/2 - \delta/2)c(O)\}$.
We argue that the following inequalities hold:

\begin{align}
\label{mmgreedy:ineq1}
c(A) \leq (0.5 + \epsilon - \delta)c(O)
\\
\label{mmgreedy:ineq2}
c(x) > (0.5 -\epsilon + \delta)c(O)
\\
\label{mmgreedy:ineq3}
c(C) \leq (0.5 + \epsilon - \delta)c(O)
\\
\label{mmgreedy:ineq5}
c(B) \geq (1/4 - 3\epsilon/2 + 3\delta/2)c(O)
\\
\label{mmgreedy:ineq4}
f(C) \geq e^{-1/2 + \epsilon}f(O)
\\
\label{mmgreedy:ineq6}
f(B|A) \geq 
(1-e^{-\frac{1-6\epsilon+6\delta}{2+4\epsilon-4\delta}})
\left[
e^{-(1/2 + \epsilon)}
- (1 - e^{-(1/2 + \epsilon - \delta)})
\right]f(O)
\\
\label{mmgreedy:ineq7}
f(T) \geq \max_\epsilon \min \{(1 - e^{-(0.5 + \epsilon)})f(O), \min_{\delta} f(A) + f(B|A)\}
\end{align}

Where inequality \ref{mmgreedy:ineq1} is due to Lemma~\ref{lemma:sub-main},
inequalities \ref{mmgreedy:ineq1}, \ref{mmgreedy:ineq2} with the definition of cheap
element implies inequality \ref{mmgreedy:ineq5},
inequality \ref{mmgreedy:ineq6} is due to Lemma~\ref{lemma:sub-main}, the definition
of $f(B|A)$ and monotonicity.
The last inequality captures the fact that either all elements in $O$ are smaller than
$(0.5 + \epsilon)c(O)$ or there is one element in $O$ larger than $(0.5 + \epsilon)c(O)$.


Substituting $(f(A) = 1 - e^{-(1/2 + \epsilon - \delta)})f(O)$ into the last inequality, using $f(B|A) \ge \left[
e^{-(1/2 + \epsilon)}
- (1 - e^{-(1/2 + \epsilon - \delta)})
\right]
(1-e^{-\frac{1-6\epsilon+6\delta}{2+4\epsilon-4\delta}})f(O)$,
and setting (say) $\epsilon = \eps$ gives the desired result 
as can be seen in Figure~\ref{fig:mmgreedy}.

\end{proof}

\begin{figure}
\caption{
\label{fig:mmgreedy}
Modified Modified Greedy Approximation Ratio ($\epsilon = \eps$)
}
\begin{tikzpicture}
\begin{axis}[
	width=\textwidth
	,domain=0:0.49
	,ymax=.7
	,xmax=.51
	,xlabel=$\delta$
	,xtick distance=0.1
	,ytick distance=0.1
	,axis lines=left
	,grid=both
	,grid style={
		draw=gray!20
	}
	,minor tick num=5
	,legend pos=south west
	,legend entries={
		$f(A)$
		,$f(B|A)$
		,$f(A) + f(B|A)$
		,$1-e^{-(0.5 + \epsilon)}$
	}
]
  \addplot[line blue]{1-exp(-(0.5 + \eps -x))};
  \addplot[line red]{
  	(1 - exp(-(1 - 6 * \eps + 6 * x)/(2 + 4 * \eps - 4 * x)))
  	*
  	(exp(-(0.5 + \eps)) - 1 + exp(-(0.5 + \eps - x)))
  };
  \addplot[line teal]{
  	1-exp(-(0.5 + \eps -x))
  	+
  	(1 - exp(-(1 - 6 * \eps + 6 * x)/(2 + 4 * \eps - 4 * x)))
  	*
  	(exp(-(0.5 + \eps)) - 1 + exp(-(0.5 + \eps - x)))
  };
  \addplot[line brown]{
  	1-exp(-(0.5 + \eps))
  };
\end{axis}
\end{tikzpicture}
\end{figure}

\textbf{Upper Bound}
We show that the approximation ratio of the modified modified greedy algorithm is at most $0.5$.
To see this consider the following instance of the budgeted maximum coverage problem:
Let the elements be $X = \{x_1, \dots, x_{2n}\}$, 
and a collection of subsets over $a$, $\mathcal{S} = \{S_1, \dots, S_{n + 1}\} \cup \{S\}$,
where for each $1 \leq i \leq n + 1$, $S_i = \{x_i\}$, and $c(S_i) = 1$. 
Also, set $S = \{x_{n + 2}, \dots, x_{2n}\}$, and $c(S) = n$.
Finally, for each $x \in X$ set $w(x) = 1$ and set the budget for this instance to be $2n$.
One can verify that the modified modified algorithm will return a solution of value $n + 1$
While taking $S$ along with any other $n$ subsets yields a solution of value $2n - 1$.  



